{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4z8PU4QjYDS"
   },
   "source": [
    "# Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyE_c8nhuS3n"
   },
   "source": [
    "## Caminhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bx0bx2xZ4IqN",
    "outputId": "63a31f5f-e088-4009-bfef-dbf4a9587400"
   },
   "outputs": [],
   "source": [
    "datasets_path     = '/home/michelms/virtualEnvPython/datasets/'\n",
    "models_path       = '/home/michelms/virtualEnvPython/models/'\n",
    "tensorboard_path  = '/home/michelms/virtualEnvPython/Tensorboard/lenet5/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2CGVK_48hDFb"
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t63l-AeYhE02"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def my_imshow(img, dataset, numImages=10):\n",
    "  \n",
    "    if dataset == 'cifar10' : \n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "    \n",
    "    img = torchvision.utils.make_grid(img[:numImages],nrow=numImages//2)\n",
    "    \n",
    "    npimg = img.numpy()    \n",
    "    npimg = np.transpose(npimg, (1, 2, 0))\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(npimg)\n",
    "    plt.show()\n",
    "\n",
    "def show_images(train_loader, test_loader, dataset, numImages=10) :\n",
    "    print('Train samples')\n",
    "    # get some random training images\n",
    "    dataiter = iter(train_loader)\n",
    "    images = dataiter.next()[0]\n",
    "    my_imshow(images, dataset, numImages)\n",
    "\n",
    "    print('Test samples')\n",
    "    # get some random training images\n",
    "    dataiter = iter(test_loader)\n",
    "    images = dataiter.next()[0]\n",
    "    my_imshow(images, dataset, numImages)\n",
    "\n",
    "def get_data_cifar10 ( batch_size , show_image=False, numImages=10 ) :\n",
    "  \n",
    "    my_transform = torchvision.transforms.Compose([\n",
    "                            torchvision.transforms.Resize(28),\n",
    "                            torchvision.transforms.ToTensor(),\n",
    "                            torchvision.transforms.Normalize(mean=[0.5],std=[0.5])\n",
    "                                    ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "                                root=f'{datasets_path}/train/', \n",
    "                                train=True, \n",
    "                                transform=my_transform, \n",
    "                                download=False\n",
    "                                )\n",
    "    test_dataset = torchvision.datasets.CIFAR10(\n",
    "                                root=f'{datasets_path}/test/',\n",
    "                                train=False, \n",
    "                                transform=my_transform, \n",
    "                                download=False\n",
    "                                )\n",
    "    train_loader = DataLoader(train_dataset, \n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True\n",
    "                                )\n",
    "    test_loader = DataLoader(test_dataset, \n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False\n",
    "                            )\n",
    "    \n",
    "    if show_image :\n",
    "        show_images(train_loader, test_loader, 'cifar10', numImages)\n",
    "    \n",
    "    return train_loader, test_loader, len(train_dataset)\n",
    "\n",
    "\n",
    "def get_data_mnist ( batch_size , show_image=False, numImages=10 ) :\n",
    "  \n",
    "    train_dataset = torchvision.datasets.mnist.MNIST(\n",
    "                            root=f'{datasets_path}/train/', \n",
    "                            train=True, \n",
    "                            transform=torchvision.transforms.ToTensor(), \n",
    "                            download=False\n",
    "                            )\n",
    "    test_dataset = torchvision.datasets.mnist.MNIST(\n",
    "                            root=f'{datasets_path}/test/',\n",
    "                            train=False, \n",
    "                            transform=torchvision.transforms.ToTensor(), \n",
    "                            download=False\n",
    "                            )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    if show_image :\n",
    "        show_images(train_loader, test_loader, 'mnist', numImages)\n",
    "    \n",
    "    return train_loader, test_loader, len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "w1xTo7PfW9T3",
    "outputId": "d855abbc-e96d-4a91-f670-8fe63ce303cd"
   },
   "outputs": [],
   "source": [
    "get_data_mnist(batch_size=256, show_image=True, numImages=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T07l5G-CjffZ"
   },
   "outputs": [],
   "source": [
    "get_data_cifar10(batch_size=256, show_image=True, numImages=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUZVS7myuD7Z"
   },
   "source": [
    "# Rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QORACe2Dgk_H"
   },
   "source": [
    "## Arquitetura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8yJxo8_LKQg"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet(nn.Module) :\n",
    "  \n",
    "    def __init__(self, num_classes=10, n_channels=1):\n",
    "        super().__init__()\n",
    "        self.c1 = nn.Conv2d(in_channels=n_channels, out_channels=6, \n",
    "                            kernel_size=(5,5), padding=2, stride=1)\n",
    "        self.s2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.activationS2 = nn.Sigmoid()\n",
    "        self.c3 = nn.Conv2d(in_channels=6, out_channels=16, \n",
    "                            kernel_size=(5,5), padding=0, stride=1)\n",
    "        self.s4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.activationS4 = nn.Sigmoid()\n",
    "        self.c5 = nn.Conv2d(in_channels=16, out_channels=120, \n",
    "                            kernel_size=(5,5), padding=0, stride=1)\n",
    "        self.activationC5 = nn.Sigmoid()\n",
    "        self.f6 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.activationF6 = nn.Tanh()\n",
    "        self.f = nn.Linear(in_features=84, out_features=num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, debug=False):\n",
    "        # Convolutional\n",
    "        if debug : print('Input',x.shape)\n",
    "        y = self.c1(x)\n",
    "        if debug : print('Outputs:')\n",
    "        if debug : print('C1',y.shape)\n",
    "        y = self.s2(y)\n",
    "        if debug : print('S2',y.shape)\n",
    "        y = self.activationS2(y)\n",
    "        if debug : print('Activation S2',y.shape)\n",
    "        y = self.c3(y)\n",
    "        if debug : print('C3',y.shape)\n",
    "        y = self.s4(y)\n",
    "        if debug : print('S4',y.shape)\n",
    "        y = self.activationS4(y)\n",
    "        if debug : print('Activation S4',y.shape)\n",
    "        # Flattening\n",
    "        y = self.c5(y)\n",
    "        if debug : print('C5',y.shape)\n",
    "        y = self.activationC5(y)\n",
    "        if debug : print('Activation C5',y.shape)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "        if debug : print('Reshape C5',y.shape)\n",
    "        # Fully Connected\n",
    "        y = self.f6(y)\n",
    "        if debug : print('F6',y.shape)\n",
    "        y = self.activationF6(y)\n",
    "        if debug : print('Activation F6',y.shape)\n",
    "        y = self.f(y)\n",
    "        if debug : print('F',y.shape)\n",
    "        s = self.softmax(y)\n",
    "        if debug : print('Softamx',s.shape)\n",
    "        return y, s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QjE_rDZOmfd6"
   },
   "source": [
    "## Informações sobre a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdSgF-6wD7__",
    "outputId": "a5085295-1a0d-45c5-f982-fe0aa0cf5703"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    my_device = torch.device(\"cpu\")\n",
    "    \n",
    "print(f\"Running on {my_device.type}.\")\n",
    "\n",
    "net = LeNet(num_classes=10, n_channels=3)\n",
    "net = net.to(my_device)\n",
    "\n",
    "a = torch.rand( (1, 3, 28, 28) )\n",
    "\n",
    "b = net( a.to(my_device) , debug=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_TfzVGVRrsL",
    "outputId": "fcd47a54-96fc-4947-f790-e05c8c0c98e8"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(net, input_size=(3,28,28), batch_size=256)\n",
    "del net, a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b13rYc5AuT1J"
   },
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMTNH0AbhSfo"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.optim \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import copy\n",
    "  \n",
    "from datetime import datetime\n",
    "\n",
    "def train ( dataset, epochs=100, lr=1e-1, prefix='', upper_bound=99.0, device='cpu',\n",
    "           save=False, debug=False, plot_histograms=False, lambda_reg=0) :\n",
    "\n",
    "    if dataset == 'mnist' :\n",
    "        batch_size = 256\n",
    "        train_loader, test_loader, dataset_size = get_data_mnist(batch_size, \n",
    "                                                                    show_image=True\n",
    "                                                                    )\n",
    "        num_classes = 10\n",
    "        n_channels = 1\n",
    "    elif dataset == 'cifar10' :\n",
    "        batch_size = 256\n",
    "        train_loader, test_loader, dataset_size = get_data_cifar10(batch_size, \n",
    "                                                                    show_image=True\n",
    "                                                                    )\n",
    "        num_classes = 10\n",
    "        n_channels = 3\n",
    "    else :\n",
    "        print('Dataset loader not implemented.')\n",
    "        return None    \n",
    "  \n",
    "    net = LeNet( num_classes, n_channels )\n",
    "    net.to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr, weight_decay=lambda_reg)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    now = datetime.now()\n",
    "    suffix = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    prefix = prefix + '-' + suffix if prefix != '' else suffix\n",
    "\n",
    "    writer = SummaryWriter( log_dir=tensorboard_path+prefix )\n",
    "    \n",
    "    writer.add_graph(net, next(iter(train_loader))[0].to(my_device))\n",
    "\n",
    "    accuracies = []\n",
    "    max_accuracy = -1.0\n",
    "\n",
    "    for epoch in tqdm( range(epochs) , desc='Training epochs...' ) :\n",
    "        net.train()  \n",
    "        for idx, (train_x, train_label) in enumerate(train_loader):\n",
    "            train_x = train_x.to(device)\n",
    "            train_label = train_label.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predict_y = net( train_x )[0]\n",
    "\n",
    "            # Loss:\n",
    "            error = loss( predict_y , train_label.long() )\n",
    "\n",
    "            writer.add_scalar( 'Loss/train', error, \n",
    "                            idx+( epoch*(dataset_size//batch_size) ) )\n",
    "\n",
    "            error.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accuracy:\n",
    "            predict_ys = torch.max( predict_y, axis=1 )[1]\n",
    "            correct    = torch.sum(predict_ys == train_label)\n",
    "\n",
    "            writer.add_scalar( 'Accuracy/train', correct/train_x.size(0), \n",
    "                            idx+( epoch*(dataset_size//batch_size) ) )\n",
    "\n",
    "            if debug and idx % 10 == 0 :\n",
    "                print(f'idx: {idx}, _error: {error}')\n",
    "\n",
    "        if plot_histograms : \n",
    "            plot_histograms_tensorboard(writer, net, epoch)\n",
    "        \n",
    "        accuracy = validate(net, test_loader, device=device)\n",
    "        accuracies.append(accuracy)\n",
    "        writer.add_scalar( 'Accuracy/test', accuracy, epoch )\n",
    "    \n",
    "        if accuracy > max_accuracy:\n",
    "            best_model = copy.deepcopy(net)\n",
    "            max_accuracy = accuracy\n",
    "            print(f'Saving Best Model with Accuracy: {max_accuracy:3.4f}')\n",
    "            \n",
    "        print( f'Epoch: {epoch+1:3d} | Accuracy : {accuracy:3.4f}%' )\n",
    "\n",
    "        if accuracy > upper_bound :\n",
    "            break\n",
    "   \n",
    "    if save : \n",
    "        path = f'{models_path}LeNet5-{dataset}-{max_accuracy:.2f}.pkl'\n",
    "        torch.save(best_model.state_dict(), path)\n",
    "        print('Model saved in:',path)\n",
    "  \n",
    "    plt.plot(accuracies)\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms_tensorboard ( writer, net, epoch ) :\n",
    "    writer.add_histogram('Bias/conv1',   net.c1.bias,        epoch)\n",
    "    writer.add_histogram('Weight/conv1', net.c1.weight,      epoch)\n",
    "    writer.add_histogram('Grad/conv1',   net.c1.weight.grad, epoch)\n",
    "\n",
    "    writer.add_histogram('Bias/conv3',   net.c3.bias,        epoch)\n",
    "    writer.add_histogram('Weight/conv3', net.c3.weight,      epoch)\n",
    "    writer.add_histogram('Grad/conv3',   net.c3.weight.grad, epoch)\n",
    "\n",
    "    writer.add_histogram('Bias/conv5',   net.c5.bias,        epoch)\n",
    "    writer.add_histogram('Weight/conv5', net.c5.weight,      epoch)\n",
    "    writer.add_histogram('Grad/conv5',   net.c5.weight.grad, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXG-IjwogweA"
   },
   "source": [
    "## Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFNT61DWgzW2"
   },
   "outputs": [],
   "source": [
    "def validate ( model , data , device='cpu') :\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    sum = 0\n",
    "    \n",
    "    for idx, (test_x, test_label) in enumerate(data) : \n",
    "        test_x = test_x.to(device)\n",
    "        test_label = test_label.to(device)\n",
    "        predict_y = model( test_x )[0].detach()\n",
    "        predict_ys = torch.max( predict_y, axis=1 )[1]\n",
    "        sum = sum + test_x.size(0)\n",
    "        correct = correct + torch.sum(predict_ys == test_label)\n",
    "    \n",
    "    return correct*100./sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuR0UzNEMCy1"
   },
   "source": [
    "# Execução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ez-wfLE-ET_3"
   },
   "source": [
    "## Treina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 835
    },
    "id": "u_naT_XMdkys",
    "outputId": "a5c02cc0-2017-4783-a9a6-f7ea0d93f244"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    my_device = torch.device(\"cpu\")\n",
    "print(f\"Running on {my_device.type}.\")\n",
    "\n",
    "epochs = 10\n",
    "dataset = 'mnist'\n",
    "# dataset = 'cifar10' \n",
    "lr = 1.3e0\n",
    "lambda_reg = 1e-4\n",
    "\n",
    "prefix = 'LeNet-{}-e-{}-lr-{}'.format(dataset, epochs, lr)\n",
    "\n",
    "net = train( dataset=dataset, epochs=epochs, lr=lr, prefix=prefix , upper_bound=100, device=my_device,\n",
    "            save=True, debug=False, plot_histograms=True, lambda_reg=lambda_reg )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36XRAIEHubdR"
   },
   "source": [
    "# Carregar Rede de arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOssniG-mWSN"
   },
   "outputs": [],
   "source": [
    "# del net\n",
    "\n",
    "path = '/home/michelms/virtualEnvPython/models/LeNet5-mnist-97.40.pkl'\n",
    "n_channels = 1\n",
    "\n",
    "def load_LeNet ( device , path ) :\n",
    "    net = LeNet(num_classes=10, n_channels=n_channels)\n",
    "    net = net.to(device)\n",
    "    net.load_state_dict(torch.load(path))\n",
    "    net.eval()\n",
    "    return net\n",
    "\n",
    "net = load_LeNet(my_device, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kynNDloueji"
   },
   "source": [
    "# Carregar dado do MNIST e inferir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "7kbmb6Hjf394",
    "outputId": "93599d6d-6dc8-4a87-f770-235eacb04780"
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "def sample_and_predict ( seed=None ) :\n",
    "\n",
    "    if seed is not None :\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    dataset = torchvision.datasets.MNIST(\n",
    "                                      root=f'{datasets_path}/test/', \n",
    "                                      train=False\n",
    "                                      )\n",
    "    i = np.random.randint(len(dataset))\n",
    "    sample = dataset[i][0]\n",
    "\n",
    "    print( 'Sample: {}'.format(i) )\n",
    "    plt.axis('off')\n",
    "    plt.imshow( sample , cmap='gray')\n",
    "    \n",
    "    x = torchvision.transforms.ToTensor()(sample).float()\n",
    "    print(x.shape)\n",
    "\n",
    "    x = x.unsqueeze_(0)\n",
    "    print(x.shape)\n",
    "\n",
    "    x = x.to(my_device)\n",
    "\n",
    "    y = net ( x )[1]\n",
    "    confidence = torch.max(y, 1)[0]\n",
    "    prediction = torch.max(y, 1)[1]\n",
    "    \n",
    "    confidence = confidence.data.cpu().numpy()[0]\n",
    "    prediction = prediction.data.cpu().numpy()[0]\n",
    "\n",
    "    return prediction, confidence, dataset[i][1]\n",
    "\n",
    "prediction, confidence, label = sample_and_predict()\n",
    "print( f'\\nPredicted clas: {prediction} \\nClassifier confidence: {confidence*100:4.2f}% \\nTrue label: {label}' )\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "rUZVS7myuD7Z",
    "QjE_rDZOmfd6",
    "36XRAIEHubdR",
    "Cf2RJcWTuigS"
   ],
   "name": "pytorch-LeNet-5-YannLecun-Paper.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
