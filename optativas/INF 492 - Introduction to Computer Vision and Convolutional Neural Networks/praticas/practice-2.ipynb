{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc99e0b",
   "metadata": {},
   "source": [
    "**Test with Iris dataset and Test and train split function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e91eded",
   "metadata": {},
   "source": [
    "### Architecture definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79367c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ANN(nn.Module) :\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(self.__class__, self).__init__()\n",
    "\n",
    "        self.fullyConnected = nn.Sequential(\n",
    "            nn.Linear(in_features=4, out_features=10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=10, out_features=20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=20, out_features=num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, debug=False):\n",
    "        if debug : print('input',x.shape)\n",
    "        y = self.fullyConnected(x)\n",
    "        if debug : print('output',y.shape)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e62a9e",
   "metadata": {},
   "source": [
    "### Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62836bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on CUDA.\")\n",
    "else:\n",
    "    my_device = torch.device(\"cpu\")\n",
    "    print(\"No Cuda Available\")\n",
    "\n",
    "net = ANN( num_classes=3 )\n",
    "\n",
    "net = net.to(my_device)\n",
    "\n",
    "a = torch.rand( (1, 4) )\n",
    "a = a.to(my_device)\n",
    "b = net( a , debug=True )\n",
    "\n",
    "del a, b, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "net = ANN( num_classes=3 )\n",
    "\n",
    "net = net.to(my_device)\n",
    "\n",
    "summary(net, input_size=(120, 4), batch_size=1)\n",
    "\n",
    "del net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ebc08",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2251ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train ( dataset, prefix=None, upper_bound=101.0, save=False, epochs=100, \n",
    "           lr=1e-1, device='cpu', debug=False, layers2tensorboard=True, lambda_reg=0 ) :\n",
    "    \n",
    "    num_classes = 3\n",
    "    \n",
    "    tensorboard_path = '' # Setar o caminho para salvar o log para o TensorBoard\n",
    "  \n",
    "    net = ANN( num_classes )\n",
    "    net.to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, weight_decay=lambda_reg)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    now = datetime.now()\n",
    "    suffix = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    prefix = suffix if prefix is None else prefix + '-' + suffix  \n",
    "\n",
    "    writer = SummaryWriter( log_dir=tensorboard_path+prefix )\n",
    "    \n",
    "    accuracies = []\n",
    "    max_accuracy = -1.0  \n",
    "    \n",
    "    data_loader = train_test_split( dataset.data,\n",
    "                                     dataset.target,\n",
    "                                     test_size=0.2,\n",
    "                                     random_state=1 )\n",
    "    \n",
    "    train_x,test_x,train_label,test_label = data_loader\n",
    "    \n",
    "    train_x = torch.from_numpy(train_x).float()\n",
    "    train_x = train_x.to(device)\n",
    "    train_label = torch.from_numpy(train_label).float()\n",
    "    train_label = train_label.to(device)\n",
    "    \n",
    "    test_x = torch.from_numpy(test_x).float()\n",
    "    test_x = test_x.to(device)\n",
    "    test_label = torch.from_numpy(test_label).float()\n",
    "    test_label = test_label.to(device)\n",
    "    \n",
    "    writer.add_graph(net, train_x)\n",
    "    \n",
    "    for epoch in tqdm( range(epochs) , desc='Training epochs...' ) :\n",
    "        \n",
    "        # Set Pytorch variables\n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "                            \n",
    "        # Forward step\n",
    "        predict_y = net( train_x )\n",
    "        \n",
    "        # Loss\n",
    "        error = criterion( predict_y , train_label.long() )\n",
    "\n",
    "        # Back propagation\n",
    "        error.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accuracies:\n",
    "        predict_ys = torch.max( predict_y, axis=1 )[1]\n",
    "        correct    = torch.sum( predict_ys == train_label )\n",
    "        accuracy_train = correct/train_x.size(0)\n",
    "        \n",
    "        accuracy_test = validate(net, test_x, test_label, device=device)\n",
    "        accuracies.append(accuracy_test)\n",
    "        \n",
    "        # Tensor board writing\n",
    "        writer.add_scalar( 'Loss/train', error.item(), epoch )\n",
    "        writer.add_scalar( 'Accuracy/train', accuracy_train, epoch )\n",
    "        writer.add_scalar( 'Accuracy/test', accuracy_test, epoch )\n",
    "\n",
    "        if layers2tensorboard :\n",
    "            plot_layers( net, writer, epoch )\n",
    "\n",
    "        # Test model\n",
    "        if accuracy_test > max_accuracy:\n",
    "            best_model = copy.deepcopy(net)\n",
    "            max_accuracy = accuracy_test\n",
    "            print(f'Saving the best model at epoch {epoch+1:3d} ' + \n",
    "                    f'with Accuracy: {accuracy_test:8.4f}%')\n",
    "      \n",
    "        if debug : print( f'Epoch: {epoch+1:3d} |' \n",
    "                         + f'Accuracy Test: {accuracy_test:3.4f}%' )\n",
    "\n",
    "        if accuracy_test > upper_bound :\n",
    "            break\n",
    "   \n",
    "    if save : \n",
    "        models_path = '' # Setar o caminho para salvar o modelo final\n",
    "        path = f'{models_path}ANN-iris-{max_accuracy:.2f}.pkl'\n",
    "        torch.save( best_model, path )\n",
    "        print( f'Model saved in: {path}' )\n",
    "  \n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(accuracies)\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c76a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate ( model , test_x, test_label , device='cpu') :\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    sum = 0\n",
    "\n",
    "    predict_y = model( test_x ).detach()\n",
    "    predict_ys = torch.max( predict_y, axis=1 )[1]\n",
    "    sum = sum + test_x.size(0)\n",
    "    correct = correct + torch.sum(predict_ys == test_label)\n",
    "  \n",
    "    return correct.to('cpu').numpy()*100./sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc4db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layers ( net , writer, epoch ) :\n",
    "    layers = list(net.fullyConnected.modules())\n",
    "\n",
    "    layer_id = 1\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, nn.Linear) :\n",
    "            writer.add_histogram(f'Bias/linear-{layer_id}', layer.bias, epoch )\n",
    "            writer.add_histogram(f'Weight/linear-{layer_id}', layer.weight, epoch )\n",
    "            writer.add_histogram(f'Grad/linear-{layer_id}', layer.weight.grad, epoch )\n",
    "            layer_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60471744",
   "metadata": {},
   "source": [
    "### Run the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc00a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device(\"cuda:0\")\n",
    "    print(\"Running on CUDA.\")\n",
    "else:\n",
    "    my_device = torch.device(\"cpu\")\n",
    "    print(\"No Cuda Available\")\n",
    "    \n",
    "dataset = 'Iris'\n",
    "epochs = 500\n",
    "lr = 1e-1\n",
    "lambda_reg = 1e-1\n",
    "prefix = 'ANN-{}-e-{}-lr-{}'.format(dataset, epochs, lr)\n",
    "\n",
    "iris = load_iris()\n",
    "dataset = iris\n",
    "\n",
    "net = train( dataset=dataset, epochs=epochs, device=my_device, \n",
    "            upper_bound=101.0, lr=lr, lambda_reg=lambda_reg,\n",
    "            layers2tensorboard=True, save=False, prefix=prefix\n",
    "           )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
