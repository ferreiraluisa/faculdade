{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb6863",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import trange\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a2214f",
   "metadata": {},
   "source": [
    "# Image Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04288e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_and_keypoints( image , kps ) :\n",
    "    cv2.drawKeypoints( image, kps, image, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS )\n",
    "\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.imshow(image, aspect='auto')\n",
    "    plt.axis('off')\n",
    "    plt.title('Keypoints and descriptors.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433bac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_images ( dataset_path, indices , id_test , ids , labels ) :\n",
    "    \n",
    "    label = (ids[id_test] - 1) // 80\n",
    "    name = dataset_path + '/jpg/' + str(label) + '/image_' + str(ids[id_test]).zfill(4) + '.jpg'\n",
    "    \n",
    "    image = cv2.imread( name )\n",
    "    image = cv2.cvtColor( image , cv2.COLOR_BGR2RGB )\n",
    "    \n",
    "    top = 0\n",
    "    show_image_label(top, image, labels[id_test], ids[id_test] )\n",
    "    \n",
    "    accuracy = 0\n",
    "    \n",
    "    for i in indices[0] :\n",
    "        label_i = labels[i]\n",
    "        name = dataset_path + '/jpg/' + str(label_i) + '/image_' + str(ids[i]).zfill(4) + '.jpg'\n",
    "\n",
    "        image = cv2.imread( name )\n",
    "        image = cv2.cvtColor( image , cv2.COLOR_BGR2RGB )\n",
    "\n",
    "        show_image_label(top, image, label_i, ids[i] )   \n",
    "        top = top + 1\n",
    "        \n",
    "    \n",
    "def show_image_label ( top, image, label , image_id ) :\n",
    "    \n",
    "    plt.figure(figsize = (5,5))\n",
    "    plt.imshow(image, aspect='auto')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'{top} - Image id {image_id} with label {label}.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4101d4",
   "metadata": {},
   "source": [
    "# Generate descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa466267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_describe_keypoints ( image, algorithm='orb' ) :\n",
    "    \n",
    "    image_gray = cv2.cvtColor( image , cv2.COLOR_BGR2GRAY )\n",
    "        \n",
    "    if algorithm == 'sift' :\n",
    "        keypoint = sift = cv2.xfeatures2d.SIFT_create()\n",
    "    \n",
    "    elif algorithm == 'orb' :\n",
    "        keypoint = cv2.ORB_create()\n",
    "   \n",
    "    else :\n",
    "        print('Error: algorithm not defined')\n",
    "        return None\n",
    "    \n",
    "    kps = keypoint.detect( image_gray, None )    \n",
    "\n",
    "    # Describing Keypoints\n",
    "    kps, descs = keypoint.compute( image_gray, kps )\n",
    "    \n",
    "    return kps, descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad07433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bovw_descriptors (image, dictionary, algorithm='orb') :\n",
    "    \n",
    "    descs = detect_and_describe_keypoints( image, algorithm=algorithm )[1]\n",
    "\n",
    "    predicted = dictionary.predict(np.array(descs, dtype=np.double))\n",
    "    \n",
    "    desc_bovw = np.histogram(predicted, bins=range(0, dictionary.n_clusters+1))[0]\n",
    "    \n",
    "    return desc_bovw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c94f5ce",
   "metadata": {},
   "source": [
    "# Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8848b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "def create_dictionary_kmeans ( vocabulary , num_cluster ) :\n",
    "  \n",
    "    print( ' -> [I] Dictionary Info:\\n', \n",
    "        '\\nTrain len: ', len(vocabulary),\n",
    "        '\\nDimension: ', len(vocabulary[0]),\n",
    "        '\\nClusters: ', num_cluster \n",
    "        )\n",
    "\n",
    "#     dictionary = KMeans( n_clusters=num_cluster )\n",
    "    dictionary = MiniBatchKMeans( n_clusters=num_cluster, batch_size=1000 )\n",
    "\n",
    "    print ( 'Learning dictionary by Kmeans...')\n",
    "    dictionary = dictionary.fit( vocabulary )\n",
    "    print ( 'Done.')\n",
    "\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af33191",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda13d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import tqdm\n",
    "\n",
    "def create_vocabulary ( dataset_path , algorithm='orb', show_image=False , debug=False ) :\n",
    "\n",
    "    mat = scipy.io.loadmat( dataset_path+'/datasplits.mat' )\n",
    "\n",
    "    ids = mat['trn1'][0] #  'val1' or 'tst1' \n",
    "    \n",
    "    if algorithm == 'orb' :\n",
    "        train_descs = np.ndarray( shape=(0,32) , dtype=float )\n",
    "    elif algorithm == 'sift' :\n",
    "        train_descs = np.ndarray( shape=(0,128) , dtype=float )\n",
    "    else :\n",
    "        print('Error:Algorithm not defined.')\n",
    "        return None\n",
    "\n",
    "    for id in tqdm.tqdm(ids, desc='Processing train set') :\n",
    "\n",
    "        label = (id - 1) // 80\n",
    "        name = dataset_path + '/jpg/' + str(label) + '/image_' + str(id).zfill(4) + '.jpg'\n",
    "\n",
    "        image = cv2.imread( name )\n",
    "        \n",
    "        if image is None:\n",
    "            print(f'Reading image Error. Path: {name}')\n",
    "            return None\n",
    "\n",
    "        kps, descs = detect_and_describe_keypoints ( image, algorithm=algorithm )\n",
    "            \n",
    "        train_descs = np.concatenate((train_descs, descs), axis=0)\n",
    "        \n",
    "        if show_image :\n",
    "            show_image_and_keypoints(image, kps)\n",
    "\n",
    "        if debug :\n",
    "            print( name )\n",
    "            print( 'Number of keypoints: ', len(kps) )\n",
    "            print( 'Number of images: ', len(ids) )\n",
    "            print( 'Descriptor size: ', len(descs[0]) )\n",
    "            print( type(descs[0]) )\n",
    "      \n",
    "    print( ' -> [I] Image Loader Info:\\n', \n",
    "      '\\nTrain len: ', len(train_descs),\n",
    "      '\\nNumber of images: ', len(ids),\n",
    "      '\\nDescriptor size: ', len(descs[0])      \n",
    "      )\n",
    "    \n",
    "    return train_descs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff15234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def represent_dataset( dataset_path, dictionary , algorithm='orb' ) :\n",
    "\n",
    "    mat = scipy.io.loadmat( dataset_path+'/datasplits.mat' )\n",
    "\n",
    "    ids = mat['tst1'][0] #  'trn1' or 'val1' \n",
    "    \n",
    "    space = []\n",
    "    labels = []\n",
    "    \n",
    "    for id in tqdm.tqdm(ids, desc='Processing train set') :\n",
    "\n",
    "        label = (id - 1) // 80\n",
    "        name = dataset_path + '/jpg/' + str(label) + '/image_' + str(id).zfill(4) + '.jpg'\n",
    "\n",
    "        image = cv2.imread( name )\n",
    "\n",
    "        desc_bovw = create_bovw_descriptors(image, dictionary, algorithm=algorithm)\n",
    "\n",
    "        space.append(desc_bovw)\n",
    "        labels.append(label)\n",
    "        \n",
    "    print( ' -> [I] Space Describing Info:\\n', \n",
    "        '\\nNumber of images: ', len(space), \n",
    "        '\\nNumber of labels: ', len(labels),\n",
    "        '\\nDimension: ', len(space[0])\n",
    "        )\n",
    "\n",
    "    return space , labels "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9b8b6e",
   "metadata": {},
   "source": [
    "# Experimental evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42375af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def run_test ( space , labels , dictionary , dataset_path, algorithm='orb', top=10 ) :\n",
    "    knn = NearestNeighbors(n_neighbors=top+1).fit(space)\n",
    "    \n",
    "    mat = scipy.io.loadmat( dataset_path+'/datasplits.mat' )\n",
    "\n",
    "    ids = mat['tst1'][0] #  'trn1' or 'val1'\n",
    "    \n",
    "    accuracy_t = 0\n",
    "    \n",
    "    for id_test in tqdm.tqdm(ids, desc='running the test phase') :\n",
    "        \n",
    "        label = (id_test - 1) // 80\n",
    "        name = dataset_path + '/jpg/' + str(label) + '/image_' + str(id_test).zfill(4) + '.jpg'\n",
    "\n",
    "        image = cv2.imread( name )\n",
    "        \n",
    "        desc_bovw = create_bovw_descriptors(image, dictionary, algorithm=algorithm)\n",
    "\n",
    "        indices = knn.kneighbors(desc_bovw.reshape(1, -1))[1]\n",
    "\n",
    "        labels_top = [ labels[i] for i in indices[0] ]\n",
    "\n",
    "        accuracy = sum( np.equal(labels_top, label) )\n",
    "        accuracy =( (accuracy-1)/(top) ) * 100 \n",
    "        accuracy_t = accuracy_t + accuracy\n",
    "        \n",
    "    print(f'Average accuracy in the test set: {accuracy_t/len(ids):5.2f}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ac2a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_single_image ( space , labels , dictionary , dataset_path, algorithm='orb', top=10 ) :\n",
    "    knn = NearestNeighbors(n_neighbors=top+1).fit(space)\n",
    "    \n",
    "    mat = scipy.io.loadmat( dataset_path+'/datasplits.mat' )\n",
    "\n",
    "    ids = mat['tst1'][0] #  'trn1' or 'val1'\n",
    "    \n",
    "    id_test = random.randrange( len(ids) )\n",
    "        \n",
    "    label = (ids[id_test] - 1) // 80\n",
    "    name = dataset_path + '/jpg/' + str(label) + '/image_' + str(ids[id_test]).zfill(4) + '.jpg'\n",
    "    \n",
    "    image = cv2.imread( name )\n",
    "\n",
    "    desc_bovw = create_bovw_descriptors(image, dictionary, algorithm=algorithm)\n",
    "    \n",
    "    distances, indices = knn.kneighbors(desc_bovw.reshape(1, -1))\n",
    "    \n",
    "    show_top_images(dataset_path, indices, id_test, ids, labels)\n",
    "    \n",
    "    labels_top = [ labels[i] for i in indices[0] ]\n",
    "    \n",
    "    accuracy = sum( np.equal( label , labels_top ) )\n",
    "    accuracy =( (accuracy-1)/(top) ) * 100 \n",
    "    \n",
    "    print(f'Accuracy for image id {ids[id_test]}: {accuracy:5.2f}%')\n",
    "    \n",
    "    print(name)    \n",
    "    print(f'Image: {ids[id_test]} with label {labels[id_test]}')    \n",
    "    print(f'Closest image: {ids[indices[0][0]]} with distance {distances[0][0]} and label {labels[indices[0][0]]}')\n",
    "    print('Distances: ',distances)\n",
    "    print('Indices: ',indices)\n",
    "    print('Labels: ',labels_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939449e",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a0c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/michelms/virtualEnvPython/datasets/flowers_classes/'\n",
    "algorithm = 'sift'\n",
    "vocabulary = create_vocabulary( dataset_path, algorithm=algorithm ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 100\n",
    "dictionary = create_dictionary_kmeans( vocabulary , num_clusters )\n",
    "space, labels = represent_dataset ( dataset_path , dictionary, algorithm=algorithm )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5695f2b",
   "metadata": {},
   "source": [
    "run_test( space, labels, dictionary, dataset_path, algorithm=algorithm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305bba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_single_image( space, labels, dictionary, dataset_path , algorithm=algorithm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
