{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLJFdPLELJ3-"
   },
   "source": [
    "# Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJ9kIdSMk84n"
   },
   "source": [
    "## Montar Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lE7w5DYUk9zq"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "root_path = '/content/gdrive/'\n",
    "drive.mount(root_path)\n",
    "\n",
    "google_drive_path = root_path + 'MyDrive/ColabData/' # alterar\n",
    "models_path       = google_drive_path + 'models/' # alterar\n",
    "tensorboard_path  = google_drive_path + 'tensorboard/ae/' # alterar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGYiDTSvLGAH"
   },
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97rpH7FflBUZ"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=$tensorboard_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cX3Yq3N2kp7K"
   },
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3o3iRb0ksSu"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def my_imshow(img):\n",
    "\n",
    "    if img.shape[1] == 3 :    # RGB image\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "\n",
    "    img = torchvision.utils.make_grid(img[:10],nrow=5)\n",
    "\n",
    "    npimg = img.numpy()\n",
    "\n",
    "    npimg = np.transpose(npimg, (1, 2, 0))\n",
    "    plt.imshow(npimg, interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_images(train_loader, test_loader) :\n",
    "    print('Train samples')\n",
    "    # get some random training images\n",
    "    dataiter = iter(train_loader)\n",
    "    images = next(dataiter)[0]\n",
    "    my_imshow(images)\n",
    "\n",
    "    print('Test samples')\n",
    "    # get some random training images\n",
    "    dataiter = iter(test_loader)\n",
    "    images = next(dataiter)[0]\n",
    "    my_imshow(images)\n",
    "\n",
    "def get_data_mnist ( batch_size, show_image=False , seed=None) :\n",
    "\n",
    "    my_transform = torchvision.transforms.Compose([\n",
    "                                    torchvision.transforms.Resize(32),\n",
    "                                    torchvision.transforms.ToTensor()\n",
    "                                    ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.mnist.MNIST(\n",
    "                                root='{}datasets/train/'.format(google_drive_path),\n",
    "                                train=True,\n",
    "                                download=False,\n",
    "                                transform=my_transform\n",
    "                                )\n",
    "    test_dataset  = torchvision.datasets.mnist.MNIST(\n",
    "                                root='{}datasets/test/'.format(google_drive_path),\n",
    "                                train=False,\n",
    "                                download=False,\n",
    "                                transform=my_transform\n",
    "                                )\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=True\n",
    "                                )\n",
    "    test_loader  = DataLoader(test_dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False\n",
    "                                )\n",
    "\n",
    "    if show_image :\n",
    "        show_images(train_loader, test_loader)\n",
    "\n",
    "    return train_loader, test_loader, len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCZ_gUJYha58"
   },
   "source": [
    "# Rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFUIw-KSuP_x"
   },
   "source": [
    "## Arquitetura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BV4FRd59gKI_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AE(nn.Module) :\n",
    "\n",
    "  def __init__(self, code, in_channels=3):\n",
    "    super().__init__()\n",
    "\n",
    "    dim1 = 16\n",
    "    dim2 = 32\n",
    "    dim3 = 64\n",
    "    code = code\n",
    "\n",
    "    self.encoder = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=in_channels, out_channels=dim1, kernel_size=(4,4), stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=dim1, out_channels=dim2, kernel_size=(4,4), stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(in_channels=dim2, out_channels=dim3, kernel_size=(4,4), stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "    )\n",
    "\n",
    "    self.linear = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(in_features=64*4*4, out_features=code),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=code, out_features=64*4*4),\n",
    "        nn.ReLU(),\n",
    "        nn.Unflatten(dim=1, unflattened_size=(64, 4, 4))\n",
    "    )\n",
    "\n",
    "    self.decoder = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=dim3, out_channels=dim2, kernel_size=(4,4), stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(in_channels=dim2, out_channels=dim1, kernel_size=(4,4), stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(in_channels=dim1, out_channels=in_channels, kernel_size=(4,4), stride=2, padding=1),\n",
    "        nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "  def forward(self, x, debug=False):\n",
    "    if debug : print('input',x.shape)\n",
    "    y = self.encoder(x)\n",
    "    if debug : print('enconder',y.shape)\n",
    "    y = self.linear(y)\n",
    "    if debug : print('sequential',y.shape)\n",
    "    y = self.decoder(y)\n",
    "    if debug : print('decoder',y.shape)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-n_ih_kP_rt"
   },
   "source": [
    "## Inicialização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3_Baol2jQCLx"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) :\n",
    "        # Weights:\n",
    "        # nn.init.constant_(m.weight.data, 0)\n",
    "        # nn.init.constant_(m.weight.data, 1)\n",
    "        # torch.nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        torch.nn.init.xavier_normal_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        # torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "        # torch.nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "\n",
    "        # Bias:\n",
    "        # nn.init.constant_(m.bias.data, 0)\n",
    "        if m.bias is not None:\n",
    "            fan_in, fan_out = nn.init._calculate_fan_in_and_fan_out(m.weight.data)\n",
    "            bound = 1 / math.sqrt(fan_out)\n",
    "            nn.init.normal_(m.bias, -bound, bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMuuVSTLlGcg"
   },
   "source": [
    "## Informações sobre a rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tM4AtSz9lNgy"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    my_device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Running on {my_device.type}.\")\n",
    "\n",
    "in_channel = 1\n",
    "net = AE( code=100, in_channels=in_channel )\n",
    "\n",
    "net = net.to(my_device)\n",
    "\n",
    "a = torch.rand( (1, in_channel, 32 , 32) )\n",
    "a = a.to(my_device)\n",
    "b = net( a , debug=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSNAaLoTlJWP"
   },
   "outputs": [],
   "source": [
    "summary(net, input_size=(in_channel,32,32), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9myZba3ujdw"
   },
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndSU_1AUOM5c"
   },
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=.4):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Qv5m8FsupCZ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import copy\n",
    "\n",
    "def plot_layers( net , epoch, writer) :\n",
    "\n",
    "    layers = list(net.encoder.modules())\n",
    "    layer_id = 1\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, nn.Conv2d) :\n",
    "\n",
    "            writer.add_histogram('Encoder/Bias/conv{}'.format(layer_id),   layer.bias,        epoch)\n",
    "            writer.add_histogram('Encoder/Weight/conv{}'.format(layer_id), layer.weight,      epoch)\n",
    "            writer.add_histogram('Encoder/Grad/conv{}'.format(layer_id),   layer.weight.grad, epoch)\n",
    "            layer_id += 1\n",
    "\n",
    "    layers = list(net.decoder.modules())\n",
    "    layer_id = 1\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, nn.ConvTranspose2d) :\n",
    "\n",
    "            writer.add_histogram('Decoder/Bias/upconv{}'.format(layer_id),   layer.bias,        epoch)\n",
    "            writer.add_histogram('Decoder/Weight/upconv{}'.format(layer_id), layer.weight,      epoch)\n",
    "            writer.add_histogram('Decoder/Grad/upconv{}'.format(layer_id),   layer.weight.grad, epoch)\n",
    "            layer_id += 1\n",
    "\n",
    "def train ( dataset='mnist', prefix=None, save=False, epochs=100, code=1024,\n",
    "           lr=1e-5, device='cpu', debug=False, layers2tensorboard=False , image2tensorboard='True') :\n",
    "\n",
    "    if dataset == 'mnist' :\n",
    "        batch_size = 128\n",
    "        train_loader, test_loader, dataset_size = get_data_mnist(batch_size, show_image=True)\n",
    "        in_channels = 1\n",
    "        criterion = nn.MSELoss()\n",
    "    else :\n",
    "        print('Error, dataloader is not implemented.')\n",
    "        return None\n",
    "\n",
    "    net = AE ( code=code, in_channels=in_channels )\n",
    "    net.apply(init_weights)\n",
    "    net.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    now = datetime.now()\n",
    "    suffix = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    prefix = suffix if prefix is None else prefix + '-' + suffix\n",
    "\n",
    "    writer = SummaryWriter( log_dir=tensorboard_path+prefix )\n",
    "\n",
    "    losses = []\n",
    "    smaller_loss = 1000.0\n",
    "\n",
    "    add_noise = AddGaussianNoise()\n",
    "\n",
    "    for epoch in range(epochs) :\n",
    "        net.train()\n",
    "        for idx, (train_x, _ ) in enumerate(train_loader):\n",
    "            train_noise_x = add_noise(train_x)\n",
    "            train_noise_x = train_noise_x.to(device)\n",
    "            train_x = train_x.to(device)\n",
    "\n",
    "            predict_y = net( train_noise_x )\n",
    "            # predict_y = net( train_x )\n",
    "\n",
    "            # Loss:\n",
    "            error = criterion( predict_y , train_x )\n",
    "\n",
    "            writer.add_scalar( 'Loss/train', error.item(), idx+( epoch*(dataset_size//batch_size) ) )\n",
    "\n",
    "            # Back propagation\n",
    "            optimizer.zero_grad()\n",
    "            error.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if debug and idx % 10 == 0 :\n",
    "                print( 'idx: {}, _error: {}'.format( idx, error.item() ) )\n",
    "\n",
    "        if layers2tensorboard :\n",
    "            plot_layers( net , epoch, writer)\n",
    "\n",
    "        loss_test = validate(net, test_loader, dataset, writer,\n",
    "                             epoch, device=device, image2tensorboard=image2tensorboard)\n",
    "        losses.append(loss_test)\n",
    "        writer.add_scalar( 'Loss/test', loss_test, epoch )\n",
    "\n",
    "        if loss_test < smaller_loss :\n",
    "            best_model = copy.deepcopy(net)\n",
    "            smaller_loss = loss_test\n",
    "            print(\"Saving Best Model with Loss: \", loss_test)\n",
    "\n",
    "        print( 'Epoch: {:3d} | Loss : {:3.4f}'.format(epoch+1, loss_test) )\n",
    "\n",
    "    if save :\n",
    "        path = '{}ae-mnist-{:.2f}.pkl'.format(models_path, smaller_loss)\n",
    "        torch.save(best_model, path)\n",
    "        print('Model saved in:',path)\n",
    "\n",
    "    plt.plot(losses)\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Hr1UXKPLVRN"
   },
   "source": [
    "## Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-dISljT2LX81"
   },
   "outputs": [],
   "source": [
    "def validate ( model , data , dataset, writer, step, device='cpu', image2tensorboard=True) :\n",
    "\n",
    "    model.eval()\n",
    "    if dataset == 'mnist' :\n",
    "        criterion = nn.MSELoss()\n",
    "    else :\n",
    "        print('Error, dataloader is not implemented.')\n",
    "        return None\n",
    "\n",
    "\n",
    "    error = 0\n",
    "    sum = 0\n",
    "    num_images = 12\n",
    "\n",
    "    add_noise = AddGaussianNoise()\n",
    "\n",
    "    for idx, (test_x, _) in enumerate(data) :\n",
    "\n",
    "        test_noise_x = add_noise(test_x)\n",
    "        test_noise_x = test_noise_x.to(device)\n",
    "\n",
    "        test_x = test_x.to(device)\n",
    "\n",
    "        with torch.no_grad() :\n",
    "            # predict_y = model( test_x ).detach()\n",
    "            predict_y = model( test_noise_x ).detach()\n",
    "        error_ = criterion( predict_y , test_x )\n",
    "        error_ = error_.item()\n",
    "        error = error + error_\n",
    "\n",
    "        if idx == 1 :\n",
    "\n",
    "            test_noise_x = test_noise_x.view(test_noise_x.size(0),\n",
    "                                             test_noise_x.size(1),\n",
    "                                             test_noise_x.size(2),\n",
    "                                             test_noise_x.size(3)).cpu().data\n",
    "            img_noise =  torchvision.utils.make_grid(test_noise_x[:num_images],\n",
    "                                                        nrow=num_images//2)\n",
    "\n",
    "            test_x = test_x.view(test_x.size(0),\n",
    "                                             test_x.size(1),\n",
    "                                             test_x.size(2),\n",
    "                                             test_x.size(3)).cpu().data\n",
    "            img_target =  torchvision.utils.make_grid(test_x[:num_images],\n",
    "                                                        nrow=num_images//2)\n",
    "\n",
    "            predict_y = predict_y.view(predict_y.size(0), predict_y.size(1), predict_y.size(2), predict_y.size(2)).cpu().data\n",
    "            img_reconstructed = torchvision.utils.make_grid(predict_y[:num_images],nrow=num_images//2)\n",
    "\n",
    "\n",
    "            print('Target')\n",
    "            my_imshow(img_target)\n",
    "\n",
    "            print('Noise input')\n",
    "            my_imshow(img_noise)\n",
    "\n",
    "            print('reconstructed')\n",
    "            my_imshow(img_reconstructed)\n",
    "\n",
    "        if image2tensorboard and idx == 1 :\n",
    "            writer.add_image('Original_images', img_noise, step)\n",
    "            writer.add_image('Reconstructed_images', img_reconstructed, step)\n",
    "\n",
    "    return error/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TivQVyJcRhH8"
   },
   "source": [
    "# Execução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbwh-avcxvub"
   },
   "source": [
    "## Treina AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_LUQxfQx685"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    my_device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Running on {my_device.type}.\")\n",
    "\n",
    "epochs = 10\n",
    "code = 1000\n",
    "prefix = 'AE-mnist'\n",
    "dataset = 'mnist'\n",
    "lr=1e-4\n",
    "\n",
    "net_mnist = train(dataset=dataset, epochs=epochs, device=my_device, lr=lr, code=code,\n",
    "            save=False, prefix=prefix, layers2tensorboard=False, image2tensorboard=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7kFaEx5c1Ia"
   },
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoSoKi_zXOg8"
   },
   "outputs": [],
   "source": [
    "def test_image_reconstruction(dataset, net, device, num_images=10):\n",
    "\n",
    "    if dataset == 'mnist' :\n",
    "        test_loader = get_data_mnist(batch_size=32)[1]\n",
    "\n",
    "    else :\n",
    "        print('Error, dataloader is not implemented.')\n",
    "        return None\n",
    "\n",
    "\n",
    "    img = next(iter(test_loader))[0]\n",
    "    # img_noise = img.to(device)\n",
    "\n",
    "    add_noise = AddGaussianNoise()\n",
    "    img_noise = add_noise(img)\n",
    "    img_noise = img_noise.to(device)\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = net( img_noise )\n",
    "\n",
    "    print(\"Originals\")\n",
    "    img_noise = img_noise.view(img_noise.size(0),\n",
    "                                    img_noise.size(1),\n",
    "                                    img_noise.size(2),\n",
    "                                    img_noise.size(3)).cpu().data\n",
    "    my_imshow(torchvision.utils.make_grid(img_noise[:num_images],\n",
    "                                          nrow=num_images//2))\n",
    "\n",
    "    print(\"Reconstructed\")\n",
    "    outputs = outputs.view(outputs.size(0),\n",
    "                                    outputs.size(1),\n",
    "                                    outputs.size(2),\n",
    "                                    outputs.size(3)).cpu().data\n",
    "    my_imshow(torchvision.utils.make_grid(outputs[:num_images],\n",
    "                                          nrow=num_images//2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_0DyzO3YbxM"
   },
   "outputs": [],
   "source": [
    "test_image_reconstruction(dataset, net_mnist, my_device, 20)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
