{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbPApI7pbK7W",
        "outputId": "0c271c91-74d6-4e8c-98d6-61ae0f95a93d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install git+https://github.com/canesche/nvcc4jupyter.git\n",
        "!git clone https://github.com/canesche/nvcc4jupyter\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/canesche/nvcc4jupyter.git\n",
            "  Cloning https://github.com/canesche/nvcc4jupyter.git to /tmp/pip-req-build-v4ksacnn\n",
            "  Running command git clone -q https://github.com/canesche/nvcc4jupyter.git /tmp/pip-req-build-v4ksacnn\n",
            "Building wheels for collected packages: ColabPlugin\n",
            "  Building wheel for ColabPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ColabPlugin: filename=ColabPlugin-blind-py3-none-any.whl size=12725 sha256=cef7ccbed3f8e7b94e2f344d653689e112898a8a139ca45135024c4f8aef1bd3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tz0e9da_/wheels/8b/84/1d/a2cfacb702e232d99d06524968290563e63fdb70a4c78ee5c4\n",
            "\u001b[33m  WARNING: Built wheel for ColabPlugin is invalid: Metadata 1.2 mandates PEP 440 version, but 'blind' is not\u001b[0m\n",
            "Failed to build ColabPlugin\n",
            "Installing collected packages: ColabPlugin\n",
            "    Running setup.py install for ColabPlugin ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: ColabPlugin was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n",
            "Successfully installed ColabPlugin-blind\n",
            "Cloning into 'nvcc4jupyter'...\n",
            "remote: Enumerating objects: 1147, done.\u001b[K\n",
            "remote: Counting objects: 100% (362/362), done.\u001b[K\n",
            "remote: Compressing objects: 100% (271/271), done.\u001b[K\n",
            "remote: Total 1147 (delta 100), reused 328 (delta 74), pack-reused 785\u001b[K\n",
            "Receiving objects: 100% (1147/1147), 35.71 MiB | 14.78 MiB/s, done.\n",
            "Resolving deltas: 100% (554/554), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp2gpshU9U1m"
      },
      "source": [
        "\n",
        "Considere que desejamos gerar um array B através de um array A de mesmo tamanho, de modo que, cada elemento `B[i]` é dado pela soma do elemento `A[i]` mais os `r` elementos anteriores à posição `i` em A mais os `r` elementos posteriores, ou seja:\n",
        "```\n",
        "for(j=i-r; j<=i+r; j++)\n",
        "    B[i]+=A[j]\n",
        "```\n",
        "O código dado a seguir já faz o cálculo do array B (armazenado em `bHost`) de forma sequencial. Escreva um kernel CUDA, bem como todo o restante do código necessário para executá-lo, de modo a permitir o cálculo de B de forma paralela.\n",
        "\n",
        "As posições inválidas no início e final do array A devem ser simplesmente descartadas durante a soma, ou seja, para cálculo de `B[10]` com `r=32`, o resultado será a soma dos elementos de `A[0]` até `A[42]`.\n",
        "\n",
        "Se atente para os seguinte requisitos:\n",
        "* O cálculo dos elementos de B deve ser realizado de forma paralela;\n",
        "* A memória compartilhada da GPU deve ser utilizada de forma a deixar a operação mais eficiente;\n",
        "* O código deve tratar corretamente arrays grandes divididos em mais de um bloco.\n",
        "\n",
        "Dicas:\n",
        "* O código abaixo utiliza a constante `RANGE` para definir o valor de `r` e a constante `BLOCKSIZE` para definir o tamanho de cada bloco do grid;\n",
        "* Por simplicidade, você pode considerar que o tamanho do array A será sempre múltiplo de `BLOCKSIZE`;\n",
        "* Considere também que o tamanho de `r` será no máximo igual à metade de `BLOCKSIZE`, ou seja, o array alocado na memória compartilhada terá tamanho igual a `2*BLOCKSIZE`, no máximo.\n",
        "* A estratégia utilizada pela versão sequencial de testar cada posição (para descobrir se é válida) não é ótima. Muitas comparações desnecessárias são realizadas ao calcular as posições intermediárias. Na versão paralela, é melhor preecher as posições inválidas com o valor 0 (zero) ao copiar os dados para a memória compartilhada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7rUJaOP0hfD",
        "outputId": "d901c954-f677-45cc-eab9-20e0038ec465",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%gpu\n",
        "#include<stdio.h>\n",
        "#include<cuda.h>\n",
        "#include<cstring>\n",
        "\n",
        "#define BLOCKSIZE 1024  //threads por bloco\n",
        "#define RANGE 512       //deslocamento utilizado para cálculo de B, coloquei para 512\n",
        "\n",
        "//Luísa de Souza Ferreira - 102026\n",
        "//Segui a ideia que você tinha me explicado em sala, cada thread irá completar um elemento da primeira metade e depois um elemento da segunda metade\n",
        "//Você tinha sugerido em colocar o range para 512 também, fiz essas duas coisas e deu certo :)\n",
        "__global__\n",
        "void createVecKernel(int* A, int* B, int n) {\n",
        "     __shared__ int s[2*BLOCKSIZE];\n",
        "     int tx = threadIdx.x;\n",
        "     int tid = blockIdx.x * blockDim.x + tx;\n",
        "     if(tid - RANGE >= 0 )\n",
        "        s[tx] = A[tid - RANGE];\n",
        "     else\n",
        "        s[tx] = 0;\n",
        "\n",
        "      if(RANGE + tid < n)\n",
        "        s[BLOCKSIZE+tx] = A[RANGE + tid];\n",
        "      else\n",
        "        s[BLOCKSIZE+tx] = 0;\n",
        "\n",
        "      __syncthreads();\n",
        "      int sum = 0;\n",
        "      for(int dist = tx ; dist <= tx + 2 * RANGE; dist++){\n",
        "          sum += s[dist];\n",
        "      }\n",
        "\n",
        "      B[tid] = sum;\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "void createVec(int* h_A, int* h_B, int n) {\n",
        " int size = n*sizeof(int);\n",
        " int *d_A;\n",
        " int *d_B;\n",
        " cudaMalloc((void **) &d_A, size);\n",
        " cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        " cudaMalloc((void **) &d_B, size);\n",
        " \n",
        " createVecKernel<<<ceil(1.0*n/BLOCKSIZE), BLOCKSIZE>>>(d_A, d_B, n);\n",
        "\n",
        " cudaMemcpy(h_B, d_B, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        " cudaFree(d_A);\n",
        " cudaFree(d_B);\n",
        "}\n",
        "\n",
        "\n",
        "void initArray(int *a, int n) {\n",
        "    for (int i =0; i<n; ++i) \n",
        "        a[i]=i;\n",
        "}\n",
        "void zeraArray(int *b, int n){\n",
        "    for(int i = 0; i < n; i++)\n",
        "        b[i] = 0;\n",
        "}\n",
        "\n",
        "\n",
        "bool checkArray(int *a, int *b, int n) {\n",
        "    for (int i =0; i<n; ++i) \n",
        "        if (a[i]!=b[i]){\n",
        "            printf(\"resultado diferente %d: %d e %d\", i, a[i], b[i]);\n",
        "            return false;\n",
        "        }\n",
        "    return true;\n",
        "}\n",
        "\n",
        "void printArray(int *a, int n) {\n",
        "    int maxPrint=20;\n",
        "    for (int i =0; i<(n>maxPrint ? maxPrint : n); ++i) \n",
        "        printf(\"%3d \",a[i]);\n",
        "    if (n>maxPrint) printf(\"... (array truncado)\");\n",
        "    printf(\"\\n\");\n",
        "}\n",
        "\n",
        "void execHost(int *A, int n, int *B) {\n",
        "    for(int i=0; i<n; i++) {\n",
        "        int soma=0;\n",
        "        for(int j=i-RANGE; j<=i+RANGE; j++)\n",
        "            if(j >= 0 && j<n)\n",
        "                soma+=A[j];\n",
        "        B[i]=soma;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int size=1<<20;           //tamanho dos arrays A e B\n",
        "    int dsize=size*sizeof(int); //tamanho dos dados\n",
        "    int *a;\n",
        "    int *b;                     //array B a ser calculado na GPU\n",
        "    int *bHost;                 //array B calculado na CPU\n",
        "    a=(int*)malloc(dsize);\n",
        "    b=(int*)malloc(dsize);\n",
        "    bHost=(int*)malloc(dsize);\n",
        "    float elapsed_time = 0;\n",
        "\n",
        "    initArray(a,size);\n",
        "    printf(\"    A: \");\n",
        "    printArray(a,size);\n",
        "\n",
        "    createVec(a,b,size);\n",
        "    printf(\"B-GPU: \");\n",
        "    printArray(b,size);\n",
        "  \n",
        "\n",
        "    printf(\"B-CPU: \");\n",
        "    execHost(a, size, bHost);\n",
        "    printArray(bHost,size);\n",
        "\n",
        "    if (checkArray(b,bHost,size))\n",
        "        printf(\"Resultados iguais\\n\");\n",
        "    else\n",
        "        printf(\"Resultados diferentes\\n\");\n",
        "\n",
        "    free(bHost);\n",
        "    free(a);\n",
        "    free(b);\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    A:   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19 ... (array truncado)\n",
            "B-GPU: 131328 131841 132355 132870 133386 133903 134421 134940 135460 135981 136503 137026 137550 138075 138601 139128 139656 140185 140715 141246 ... (array truncado)\n",
            "B-CPU: 131328 131841 132355 132870 133386 133903 134421 134940 135460 135981 136503 137026 137550 138075 138601 139128 139656 140185 140715 141246 ... (array truncado)\n",
            "Resultados iguais\n",
            "\n"
          ]
        }
      ]
    }
  ]
}